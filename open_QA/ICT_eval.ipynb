{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T08:51:04.104405Z",
     "start_time": "2021-03-16T08:51:02.848993Z"
    }
   },
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, TensorDataset)\n",
    "\n",
    "from IR.mix_LM import Config, BertMultiTask_ICT as BertMultiTask\n",
    "#from IR.transformer import Config, BertMultiTask_ICT as BertMultiTask\n",
    "\n",
    "import transformers\n",
    "from transformers.data.processors.squad import SquadV2Processor\n",
    "from transformers import squad_convert_examples_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T08:51:04.208390Z",
     "start_time": "2021-03-16T08:51:04.106582Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "max_seq_length = 384\n",
    "max_query_length = 64\n",
    "doc_stride = 128\n",
    "model_file = 'IR/model.bin'\n",
    "#config_file = 'IR/transformer_config.json'\n",
    "config_file = 'IR/mix_LM_config.json'\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T08:51:04.222977Z",
     "start_time": "2021-03-16T08:51:04.210490Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed():\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "def _check_is_max_context(doc_spans, cur_span_index, position):\n",
    "    best_score = None\n",
    "    best_span_index = None\n",
    "    for (span_index, doc_span) in enumerate(doc_spans):\n",
    "        end = doc_span.start + doc_span.length - 1\n",
    "        if position < doc_span.start:\n",
    "            continue\n",
    "        if position > end:\n",
    "            continue\n",
    "        num_left_context = position - doc_span.start\n",
    "        num_right_context = end - position\n",
    "        score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n",
    "        if best_score is None or score > best_score:\n",
    "            best_score = score\n",
    "            best_span_index = span_index\n",
    "\n",
    "    return cur_span_index == best_span_index\n",
    "\n",
    "def check_answer(sim, contexts, answer, valid_rank=100) :\n",
    "    \"get accuracy based on given similarity score\"\n",
    "    sim = np.flip(np.argsort(sim, axis=1), axis=1)[:, :valid_rank]\n",
    "    hits = []\n",
    "    for a, s in zip(answer, sim) :\n",
    "        hit = []\n",
    "        for i in s :\n",
    "            hit.append((a in contexts[i]))\n",
    "        hits.append(hit)\n",
    "    hits = np.array(hits)\n",
    "    true_hit = np.zeros(hits.shape[0])!=0\n",
    "    hit_rates = []\n",
    "    for i in range(valid_rank) :\n",
    "        true_hit = (hits[:, i].reshape(-1))|true_hit\n",
    "        hit_rates.append(round((np.sum(true_hit)/len(true_hit))*100, 2))\n",
    "        print(\"{} rank : {}\".format(i+1, hit_rates[-1]))\n",
    "    print('')\n",
    "    return hit_rates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T08:51:18.492019Z",
     "start_time": "2021-03-16T08:51:04.224530Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140/140 [00:01<00:00, 78.65it/s]\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "tokenizer = transformers.ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "\n",
    "config = Config.from_json_file(config_file)\n",
    "config.vocab_size = tokenizer.vocab_size\n",
    "config.max_seq_length = max_seq_length\n",
    "\n",
    "model = BertMultiTask(config, train_mode='ict')\n",
    "model.load_state_dict(torch.load(model_file))\n",
    "model.to(device)\n",
    "\n",
    "input_file = 'data/KorQuAD_v1.0_dev.json'\n",
    "processor = SquadV2Processor()\n",
    "input_a = input_file.split('/')\n",
    "examples = processor.get_train_examples(''.join(input_a[:-1]), filename=input_a[-1])\n",
    "\n",
    "\n",
    "para_d = \"\"\n",
    "c_data, q_data, a_data = [], [], []\n",
    "for ex in examples:\n",
    "    ' '.join(ex.doc_tokens)\n",
    "    if para_d != ex.context_text:  # 문서가 바뀌었는지 체크하여 문서 번호 체크\n",
    "        para_d = ex.context_text\n",
    "        c_data.append([para_d, tokenizer.tokenize(para_d)])\n",
    "    \n",
    "    q_text = ex.question_text\n",
    "    q_data.append([q_text, tokenizer.tokenize(q_text)])\n",
    "    \n",
    "    a_text = ex.answer_text\n",
    "    a_data.append(a_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T08:51:19.756466Z",
     "start_time": "2021-03-16T08:51:18.495080Z"
    }
   },
   "outputs": [],
   "source": [
    "c_features = []\n",
    "for cd, ct in c_data:\n",
    "    \n",
    "    all_doc_tokens = [t for t in ct]\n",
    "    max_tokens_for_doc = max_seq_length - 2\n",
    "    \n",
    "    _DocSpan = collections.namedtuple(\n",
    "            \"DocSpan\", [\"start\", \"length\"])\n",
    "    doc_spans = []\n",
    "    start_offset = 0\n",
    "    while start_offset < len(all_doc_tokens):\n",
    "        length = len(all_doc_tokens) - start_offset\n",
    "        if length > max_tokens_for_doc:\n",
    "            length = max_tokens_for_doc\n",
    "        doc_spans.append(_DocSpan(start=start_offset, length=length))\n",
    "        if start_offset + length == len(all_doc_tokens):\n",
    "            break\n",
    "        start_offset += min(length, doc_stride)\n",
    "    \n",
    "    for (doc_span_index, doc_span) in enumerate(doc_spans):\n",
    "        c_tokens = []\n",
    "        c_tokens.append(tokenizer.cls_token)\n",
    "        token_to_orig_map = {}\n",
    "        token_is_max_context = {}\n",
    "        for i in range(doc_span.length):\n",
    "            split_token_index = doc_span.start + i\n",
    "            token_to_orig_map[len(c_tokens)] = split_token_index\n",
    "\n",
    "            is_max_context = _check_is_max_context(doc_spans, doc_span_index,\n",
    "                                                   split_token_index)\n",
    "            token_is_max_context[len(c_tokens)] = is_max_context\n",
    "            c_tokens.append(all_doc_tokens[split_token_index])\n",
    "        c_tokens.append(tokenizer.sep_token)\n",
    "    \n",
    "        c_input_ids = [tokenizer.convert_tokens_to_ids(t) for t in c_tokens]\n",
    "        c_input_mask = [1] * len(c_input_ids)\n",
    "    \n",
    "        while len(c_input_ids) < max_seq_length:\n",
    "            c_input_ids.append(0)\n",
    "            c_input_mask.append(0)\n",
    "        \n",
    "        assert len(c_input_ids) == max_seq_length\n",
    "        assert len(c_input_mask) == max_seq_length\n",
    "        \n",
    "        c_features.append({\n",
    "            \"text\" : cd,\n",
    "            \"input_ids\" : c_input_ids, \n",
    "            \"attention_mask\" : c_input_mask,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T08:51:19.996921Z",
     "start_time": "2021-03-16T08:51:19.759262Z"
    }
   },
   "outputs": [],
   "source": [
    "q_features = []\n",
    "for qd, qt in q_data:\n",
    "    \n",
    "    max_tokens_for_que = max_query_length - 2\n",
    "\n",
    "    if len(qt) > max_tokens_for_que:\n",
    "        qt = qt[0:max_tokens_for_que]\n",
    "    \n",
    "    q_tokens, q_segment_ids = [], []\n",
    "    q_tokens.append(tokenizer.cls_token)\n",
    "    for i in range(len(qt)):\n",
    "        q_tokens.append(qt[i])\n",
    "    q_tokens.append(tokenizer.sep_token)\n",
    "    \n",
    "    q_input_ids = [tokenizer.convert_tokens_to_ids(t) for t in q_tokens]\n",
    "    q_input_mask = [1] * len(q_input_ids)\n",
    "    \n",
    "    while len(q_input_ids) < max_query_length:\n",
    "        q_input_ids.append(0)\n",
    "        q_input_mask.append(0)\n",
    "        \n",
    "    assert len(q_input_ids) == max_query_length\n",
    "    assert len(q_input_mask) == max_query_length\n",
    "\n",
    "    q_features.append({\n",
    "        \"text\" : qd,\n",
    "        \"input_ids\" : q_input_ids, \n",
    "        \"attention_mask\" : q_input_mask,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T08:51:20.037520Z",
     "start_time": "2021-03-16T08:51:20.001793Z"
    }
   },
   "outputs": [],
   "source": [
    "q_input_ids = torch.tensor([f['input_ids'] for f in q_features], dtype=torch.long)\n",
    "q_input_mask = torch.tensor([f['attention_mask'] for f in q_features], dtype=torch.long)\n",
    "q_dataset = TensorDataset(q_input_ids, q_input_mask)\n",
    "\n",
    "c_input_ids = torch.tensor([f['input_ids'] for f in c_features], dtype=torch.long)\n",
    "c_input_mask = torch.tensor([f['attention_mask'] for f in c_features], dtype=torch.long)\n",
    "c_dataset = TensorDataset(c_input_ids, c_input_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T08:51:20.048473Z",
     "start_time": "2021-03-16T08:51:20.040148Z"
    }
   },
   "outputs": [],
   "source": [
    "c_dataloader = DataLoader(c_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "q_dataloader = DataLoader(q_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T08:51:45.038312Z",
     "start_time": "2021-03-16T08:51:20.051805Z"
    }
   },
   "outputs": [],
   "source": [
    "n_ans_ids = [tokenizer.cls_token_id, tokenizer.sep_token_id]\n",
    "n_ans_mask = [1] * len(n_ans_ids)\n",
    "while len(n_ans_ids) < max_seq_length:\n",
    "    n_ans_ids.append(0)\n",
    "    n_ans_mask.append(0)\n",
    "\n",
    "context_embedding = []\n",
    "question_embedding = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    n_ans = torch.tensor([n_ans_ids, n_ans_mask], dtype=torch.long)\n",
    "    n_ans = tuple(t.to(device) for t in n_ans)\n",
    "    n_ans_ids, n_ans_mask = n_ans\n",
    "    c_encode = model.bert(input_ids = n_ans_ids.unsqueeze(0), attention_mask = n_ans_mask.unsqueeze(0))\n",
    "    c_encode_pooled = model.decoder(c_encode)\n",
    "    context_embedding.append(c_encode_pooled)\n",
    "    \n",
    "    for step, batch in enumerate(c_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        c_input_ids, c_input_mask = batch\n",
    "        c_encode = model.bert(input_ids = c_input_ids, attention_mask = c_input_mask)\n",
    "        c_encode_pooled = model.decoder(c_encode)\n",
    "        context_embedding.append(c_encode_pooled)\n",
    "    context_embedding = torch.cat(context_embedding, 0)\n",
    "    for step, batch in enumerate(q_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        q_input_ids, q_input_mask = batch\n",
    "        q_encode = model.bert(input_ids = q_input_ids, attention_mask = q_input_mask)\n",
    "        q_encode_pooled = model.decoder(q_encode)\n",
    "        question_embedding.append(q_encode_pooled)\n",
    "    question_embedding = torch.cat(question_embedding, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T08:51:45.050355Z",
     "start_time": "2021-03-16T08:51:45.042616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IR 성능\n"
     ]
    }
   ],
   "source": [
    "print('IR 성능')\n",
    "context_text = ['']\n",
    "for i in c_features:\n",
    "    context_text.append(i[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T08:51:45.489886Z",
     "start_time": "2021-03-16T08:51:45.052416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 rank : 65.4\n",
      "2 rank : 77.85\n",
      "3 rank : 83.82\n",
      "4 rank : 86.77\n",
      "5 rank : 88.9\n",
      "6 rank : 90.51\n",
      "7 rank : 91.6\n",
      "8 rank : 92.54\n",
      "9 rank : 93.26\n",
      "10 rank : 93.8\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65.4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_sim = torch.matmul(question_embedding, context_embedding.t()).detach().cpu().numpy()\n",
    "check_answer(semantic_sim, context_text, a_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T08:51:45.501678Z",
     "start_time": "2021-03-16T08:51:45.491533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의로 지명수배된 사람의 이름은?\n",
      "[91.27508544921875, 89.81043243408203, 87.6229019165039, 87.38345336914062, 85.51984405517578, 85.10320281982422, 84.95995330810547, 84.68521118164062, 84.68035125732422, 84.18185424804688]\n",
      "박정희 정부로부터 질산 테러 등의 탄압을 받았다고 주장했다. 1979년 10월에는 YH 무역 여공 농성 사건 이후 타임과의 인터뷰에서 미국에 박정희 정권에 대한 지지를 철회할 것을 주장하였다. 유신정권은 이 발언을 문제삼아 의원직 제명 파동을 일으켜 부마항쟁을 촉발했다. 1983년에는 5.18 광주 민주화 운동 기념일을 기해 23일 동안 단식투쟁에 돌입했다. 6월 민주 항쟁 이후 통일민주당 총재로 민주화추진협의회를 구성해 민주진영을 구축했다. 1986년 대통령 직선제 개헌 1천만 서명운동을 전개하였다. 1990년 민주정의당-통일민주당-신민주공화당 3당 합당을 선언하여 민주자유당 대표최고위원으로 추대되었다. 1993년 제14대 대통령에 취임하며 32년만에 군사 정권의 마침표를 찍었고, 문민 정부를 열었다. 예술인과 작가들의 반정부와 사회비판을 허용하였다.\n",
      "\n",
      "1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률위반)으로 지명수배되었다. 1989년 3월 12일 서울지방검찰청 공안부는 임종석의 사전구속영장을 발부받았다. 같은 해 6월 30일 평양축전에 임수경을 대표로 파견하여 국가보안법위반 혐의가 추가되었다. 경찰은 12월 18일~20일 사이 서울 경희대학교에서 임종석이 성명 발표를 추진하고 있다는 첩보를 입수했고, 12월 18일 오전 7시 40분 경 가스총과 전자봉으로 무장한 특공조 및 대공과 직원 12명 등 22명의 사복 경찰을 승용차 8대에 나누어 경희대학교에 투입했다. 1989년 12월 18일 오전 8시 15분 경 서울청량리경찰서는 호위 학생 5명과 함께 경희대학교 학생회관 건물 계단을 내려오는 임종석을 발견, 검거해 구속을 집행했다. 임종석은 청량리경찰서에서 약 1시간 동안 조사를 받은 뒤 오전 9시 50분 경 서울 장안동의 서울지방경찰청 공안분실로 인계되었다.\n",
      "\n",
      "이와 같이 조선을 둘러싸고 러시아, 일본, 청나라 간의 각축전이 벌어지는 속에서 명성황후는 정부와 권력의 안정에 모든 역량을 쏟았다. 이 와중에 최제우가 일으킨 동학은 비록 민중을 거짓말로 홀렸다는 죄목을 받은 최제우가 처형되었으나 제2대 교주인 최시형을 중심으로 재기했다. 1893년 3월 충청도 보은 집회에서는 농민들이 2만여명 모여 농민을 괴롭히는 지방관들의 퇴출과 민생고를 탕감하고, 오랑캐들을 몰아낼 것 등을 요구하였고, 전봉준을 중심으로 1894년 1월에는 고부군수 조병갑의 부패를 규탄하는 농민 운동이 일어났다. 명성황후는 온건 개화파 및 친척 척신들과 가까이 지내며 그들이 동학 농민군을 동비(東匪. 동학의 불한당들.)로 보고한 것을 그대로 믿고 지냈다.\n",
      "\n",
      "이듬해 1994년에는 김문수, 이재오, 안상수, 등 시민사회운동가와 노동운동가들을 영입하여 민주자유당에 입당시켰다. 이후 군사정권과 관련 없는 홍준표·오세훈 등의 신진 관료출신과 법관출신들도 등용하였고, 군사정권에서 정치범으로 수감되었던 박노해·김남주 등 언론인과 문인들을 대대적으로 감형, 석방시키기도 하였다. 이후 4월 15일에는 3대 정치개혁 법안(공직선거 및 선거부정방지법, 정치자금법 개정안, 지방자치법 개정안)에 서명함에 따라 대한민국 민주주의의 공고화를 위한 제도 구축의 전기를 이룩했다. 1994년 여름, 미국의 빌 클린턴 행정부가 조선민주주의인민공화국의 영변 원자로 시설에 대한 정밀폭격을 검토하자 그는 이에 대한 강경한 반대입장을 펴서 저지하였다고 전해진다.\n",
      "\n",
      "하페즈 알아사드의 후계자 문제는 1998년 시리아 인민 의회 선거 이후 폭력적인 시위와 무력 충돌을 일으키며 1999년 라타키아 시위로 발전하였다. 이 사건은 하페즈 알아사드와 그의 동생 리파트 알아사드 사이에 몇 년 간 축적된 불화가 폭발한 사건이었다. 시리아 경찰은 라타키아의 리파트 항만 시설에 대한 단속을 벌였고, 이 과정에서 경찰과 리파트 알아사드 지지자들과의 총격전이 벌어져 2명이 살해되었다. 정부 측은 부정하고 있으나, 이 사건의 사상자가 수백명에 달했다는 추측이 있다. 하페즈 알아사드는 간질성 폐질환으로 1년 뒤 사망했으며, 하페즈 알아사드의 아들인 바샤르 알아사드가 대통령이 될 수 있는 나이 규정인 40세를 당시 그의 나이인 34세로 인하하도록 헌법을 수정한 후, 후계자가 되었다. 그의 아버지인 하페즈 알아사드를 이어 대통령이 된 바샤르 알아사드와 영국에서 태어나 교육을 받은 수니파 무슬림인 그의 아내 아스마 알아사드는 초기에는 민주주의를 실현하고 국가를 개혁하겠다는 희망을 시리아에 불어넣었다. 이 영향으로 2000년 7월부터 2001년 8월 사이 다마스쿠스의 봄이라는 강렬한 사회적, 정치적 논쟁이 시작된다. 이 기간에는 같은 생각을 가진 사람들끼리 모여 정치적, 사회적 문제에 대해 의논하는 살롱과 같은 다수의 정치 포럼이 만들어지고 왕성한 활동을 보였다. 이 때 리아드 세이프, 하이트함 알말레흐, 카말 알라브와니, 리야드 알투르크, 아레프 달리아와 같은 다양한 정치운동가가 이 운동을 이끌었다. 이 당시 가장 유명했던 포럼으로는 리아드 세이프 포럼, 자말 알아타시 포럼이 있다. 다마스쿠스의 봄은 2001년 8월 민주 선거를 요구하고 시민 불복종 운동을 지휘했던 운동가 10명이 체포되면서 끝나게 되었다. 2001년 이후 의회 내 개혁론자들은 전 대통령이었던 하페즈 알아사드의 통치 이후 이어진 경제 침체에 대해 비판했다. 바샤르 알아사드는 개혁에 대해 말은 하고 있으나 실제로는 거의 진행하고 있지 않으며, 2000년대 약속했던 개혁을 거의 하고 있지 않다.\n",
      "\n",
      "서울형사지방법원 합의22부 재판장으로 재직하던 1991년 3월 15일 음주운전을 하다 택시를 잡으려고 차도에 내려와 있던 시민을 치어 전치 3주의 상처를 입히고 도주하여 구속됐다가 적부심에서 석방된 가수 이동원에 대해 징역1년 집행유예2년 선고했다. 5월 10일 특가법 뇌물죄를 적용해 구속된 신민당 이재근과 이돈만, 민자당 박진구 등 국회의원 3명에 대해 \"유관단체의 경비 지원을 받는 것이 관행이라고 하나 이는 정당화될 수 없다\"며 \"다만 이 사건을 계기로 국회 차원의 윤리규정이 만들어지는 등 자정의 노력이 있은 점 등을 참작했다\"는 이유로 징역3년 집행유예4년과 징역2년6월 집행유예3년을 각각 선고했다. 5월 17일 현직 판사와의 술자리 합석 사건을 법정에서 폭로하여 물의를 빚은 폭력조직 진술파 두목에게 범죄단체 조직죄 등을 적용해 징역7년을 선고했다. 7월 16일 범민련 남측본부 준비위원회 결성으로 이창복 집행위원장과 집행위원에게 각각 징역2년6월 자격정지3년을 선고했으며 8월 21일에 서울민족미술운동연합 사건으로 구속된 단체 의장에게 징역2년 자격정지2년을 선고하면서 단체 회원에게는 징역1년6월 자격정지1년6월 집행유예3년을 선고했으며 1992년 1월 7일에 전대협 산하 조국의 평화와 자주적 통일을 위한 학생 추진위원회 위원장에 대해 징역5년 자격정지3년을 선고했다.\n",
      "\n",
      "오세훈 후보는 세운상가와 동대문 운동장 철거, 강북 중심의 뉴타운 50곳 건설 등 강북 개발과 경유버스를 천연가스 버스로 교체하고 오래된 화물차를 폐기 유도한다는 대기질 개선 공약을 내걸었다. 한편, 오세훈이 변호사 시절 찍었던 정수기 CF가 선거일 90일 전부터 본인이 등장하는 동영상, 사진 광고를 금지한 선거법을 위반했다는 이유로 고소되기도 했다. 5월 21일 오세훈 후보의 유세를 돕던 박근혜 대표가 신촌 현대백화점 앞에서 지충호에게 문구용 칼로 습격당했다. 이후 지지율 격차는 더 벌어지면서 제4회 지방 선거에서 오세훈은 2,409,760표(61.05%)를 득표하며 1,077,890표(27.31%)를 얻은 강금실을 제치고 서울시장에 당선되었다.\n",
      "\n",
      "1992년 3월에는 노동조합 간부에 대해 제기된 국가보안법 7조5항(이적표현물 제작·소지·배포 위반 상고심에서 \"‘결과적으로’ 반국가단체를 이롭게 할 수도 있다는 ‘미필적 인식’만 있으면 처벌할 수 있다\"는 다수의견과 달리 “이같은 판단기준은 추상적이고 애매모호하여 어느 정도의 표현이 법에 의하여 규제되고 처벌대상이 되는지 예측할 수 없게 만든다”며 “불법성의 판단기준이 구체적으로 밝혀져야 한다”고 하면서 “피의자의 고의성만을 판단해 처벌하게 되면 헌법상 보장된 사상과 양심의 자유를 위협하는 요소로 작용할 수 있다, 유해한 사상과 이념이라 할지라도 가급적 자유경쟁의 시장에서 비판되고 도태되는 과정을 거치게 해야 한다. 이적행위의 요건이 전혀 특정되지 않아 구성요건적 행위의 정형성이 결여됨으로써 죄형의 명확성을 요구하는 죄형법정주의에 반한다. 북한의 선전내용을 찬양·고무하는 행위라도 대한민국의 존립을 파괴할 구체적이고 가능한 위험이 있는 행위라고 보기 어려울 때는 불법성을 부인할 수밖에 없다\"며 법 운용 상의 위헌요소와 인권침해 가능성을 지적하며 법 적용범위를 엄격히 할 것을 주장하는 소수의견을 냈다. 이는 1995년 사회민주주의청년연맹 사건으로 구속기소된 최형록이나 전국연합 상임의장 이창복 사건 등에 있어 소장판사들이 일부 국가보안법 위반사범에 대해 무죄판결을 내리는 근거가 되어 사법부 내에서 국가보안법 위헌논쟁을 불러왔다. 하지만 정계 입문하고 나서 김대중 정부에서 대통령이 8.15경축사에서 밝힌 국가보안법 개정방침에 대해 강력하게 반대했다.\n",
      "\n",
      "2001년 말 제16대 대통령 선거에 공식 출마를 선언했다. 비록 세풍, 총풍 사건이 있었지만 2002년 대통령 선거 직전에도 이회창의 대쪽같은 이미지, 흔들리는 한나라당을 수호해낸 인물, 할 말은 하는 사람이라는 인식까지는 흔들리지 않았다. 새천년민주당의 당내 경선에서부터 돌풍을 몰고온 노무현 후보의 등장으로 이회창 후보의 초반 분위기는 좋지 않았다. 민주당 내에서도 무명이었던 노무현의 등장 과정과 달리 이회창은 1997년 대선 때부터 실질적인 한나라당의 지도자였으며, 사실상 2002년 대선 후보로 이미 내정된 상태였다. 당시의 노무현 후보가 노사모의 도움과 국회의원 시절의 독특한 정치행보, 서민 위주의 정책을 통해 서민적인 이미지를 구축해 나갔다면, 이회창 후보는 엘리트 코스로만 승승장구하며 달려온 정치가, 지난 30여 년간 집권 세력이었던 한나라당을 거느리고 있는 귀족적인 정치가의 이미지를 구축해 나갔다. 이런 상황을 극복하기 위해 여러 가지 '서민적인' 행보를 하던 이회창 후보는 서민적 이미지 만들기에는 실패한다. 노사모에 비견될만한 팬클럽인 창사랑 역시 노사모 만큼 활발한 활동을 보이지는 못했다.\n",
      "\n",
      "전두환 정권의 기피인물로 지목되어 연임이 안 된 채 1986년 4월 대법관직에서 퇴임하였다. 그 뒤 제6공화국이 출범하면서 1988년 7월 복직, 대법원 대법관 임명되었으며 동시에 같은 달인 7월에 중앙선거관리위원장에 임명, 선관위원장을 겸임하였다. 임명된 그는 당시 동해시와 영등포 재선거에서 당선자 대부분을 선거법 위반 혐의로 고발하여 당시 만연된 불법 선거 풍토에 경종을 울렸다. 1989년 민정, 평민, 민주, 공화 4당의 입후보자 전원을 불법 선거혐의로 고발했다. 갖가지 부정선거 사실을 고발, 재선거에서 노태우 대통령 등 민자당 내 서한을 공개적으로 문제시하였으며, 또한 김영삼 민주당 총재에게 서면으로 경고를 하기도 하였다. 이회창은 노태우 대통령의 서한이 당시 여권 내에서 크게 문제가 되자, 1년 4개월만인 1989년 11월 노태우 대통령에게 경고서한을 보내고 스스로 사표를 제출하였다. 한편 노태우는 그에게 사람을 보내 민주정의당으로 영입하려 하였으나 그는 거절했다. 그 뒤 그는 변호사 사무소를 개설하여 변호사로 활동했다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 샘플링 실험\n",
    "index = 5\n",
    "num_topk = 10\n",
    "print(q_features[index][\"text\"])\n",
    "cs = torch.matmul(question_embedding[index], context_embedding.t())\n",
    "print(torch.topk(cs, k=num_topk, dim=-1)[0].tolist())\n",
    "topk = torch.topk(cs, k=num_topk, dim=-1)[1].tolist()\n",
    "for i in topk:\n",
    "    print(c_features[int(i-1)][\"text\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T08:51:46.229181Z",
     "start_time": "2021-03-16T08:51:45.504975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF 성능\n",
      "1 rank : 71.35\n",
      "2 rank : 80.38\n",
      "3 rank : 84.29\n",
      "4 rank : 86.32\n",
      "5 rank : 87.81\n",
      "6 rank : 88.74\n",
      "7 rank : 89.42\n",
      "8 rank : 90.04\n",
      "9 rank : 90.58\n",
      "10 rank : 90.84\n",
      "11 rank : 91.27\n",
      "12 rank : 91.51\n",
      "13 rank : 91.79\n",
      "14 rank : 91.95\n",
      "15 rank : 92.15\n",
      "16 rank : 92.29\n",
      "17 rank : 92.43\n",
      "18 rank : 92.55\n",
      "19 rank : 92.62\n",
      "20 rank : 92.74\n",
      "21 rank : 92.85\n",
      "22 rank : 92.97\n",
      "23 rank : 93.09\n",
      "24 rank : 93.25\n",
      "25 rank : 93.37\n",
      "26 rank : 93.45\n",
      "27 rank : 93.51\n",
      "28 rank : 93.56\n",
      "29 rank : 93.64\n",
      "30 rank : 93.78\n",
      "31 rank : 93.82\n",
      "32 rank : 93.9\n",
      "33 rank : 93.94\n",
      "34 rank : 93.99\n",
      "35 rank : 94.02\n",
      "36 rank : 94.02\n",
      "37 rank : 94.09\n",
      "38 rank : 94.09\n",
      "39 rank : 94.16\n",
      "40 rank : 94.2\n",
      "41 rank : 94.22\n",
      "42 rank : 94.27\n",
      "43 rank : 94.34\n",
      "44 rank : 94.42\n",
      "45 rank : 94.42\n",
      "46 rank : 94.46\n",
      "47 rank : 94.49\n",
      "48 rank : 94.53\n",
      "49 rank : 94.54\n",
      "50 rank : 94.6\n",
      "51 rank : 94.61\n",
      "52 rank : 94.61\n",
      "53 rank : 94.61\n",
      "54 rank : 94.7\n",
      "55 rank : 94.77\n",
      "56 rank : 94.8\n",
      "57 rank : 94.82\n",
      "58 rank : 94.82\n",
      "59 rank : 94.86\n",
      "60 rank : 94.89\n",
      "61 rank : 94.89\n",
      "62 rank : 94.91\n",
      "63 rank : 94.91\n",
      "64 rank : 94.94\n",
      "65 rank : 94.98\n",
      "66 rank : 94.99\n",
      "67 rank : 94.99\n",
      "68 rank : 95.01\n",
      "69 rank : 95.01\n",
      "70 rank : 95.01\n",
      "71 rank : 95.01\n",
      "72 rank : 95.01\n",
      "73 rank : 95.01\n",
      "74 rank : 95.01\n",
      "75 rank : 95.01\n",
      "76 rank : 95.01\n",
      "77 rank : 95.01\n",
      "78 rank : 95.01\n",
      "79 rank : 95.03\n",
      "80 rank : 95.03\n",
      "81 rank : 95.03\n",
      "82 rank : 95.06\n",
      "83 rank : 95.08\n",
      "84 rank : 95.08\n",
      "85 rank : 95.1\n",
      "86 rank : 95.1\n",
      "87 rank : 95.17\n",
      "88 rank : 95.19\n",
      "89 rank : 95.27\n",
      "90 rank : 95.27\n",
      "91 rank : 95.31\n",
      "92 rank : 95.32\n",
      "93 rank : 95.34\n",
      "94 rank : 95.34\n",
      "95 rank : 95.38\n",
      "96 rank : 95.38\n",
      "97 rank : 95.39\n",
      "98 rank : 95.43\n",
      "99 rank : 95.43\n",
      "100 rank : 95.43\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71.35"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('TF-IDF 성능')\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "ques_text = []\n",
    "for i in q_data:\n",
    "    ques_text.append(i[0])\n",
    "    \n",
    "#answ_text = []\n",
    "#for i in q_data:\n",
    "#    answ_text.append(i[2])\n",
    "\n",
    "context_text = []\n",
    "for i in c_data:\n",
    "    context_text.append(i[0])\n",
    "\n",
    "#ques_text = []\n",
    "#for i in q_features:\n",
    "#    ques_text.append(i[0])\n",
    "    \n",
    "ngram = 2\n",
    "tfidf = TfidfVectorizer(analyzer=str.split\n",
    "                            , encoding=\"utf-8\"\n",
    "                            , stop_words=\"korean\"\n",
    "                            , ngram_range=(1, 2))\n",
    "\n",
    "tfidf_context = tfidf.fit_transform([context for context in context_text])\n",
    "tfidf_question = tfidf.transform(ques_text)\n",
    "tfidf_sim = cosine_similarity(tfidf_question, tfidf_context)\n",
    "check_answer(tfidf_sim, context_text, a_data, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
